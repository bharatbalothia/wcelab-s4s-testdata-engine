{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S4S Test Data Generator\n",
    "\n",
    "This program generate test data\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration values\n",
    "\n",
    "Configure the values below for \n",
    "\n",
    "- Input data directory\n",
    "- Output directory\n",
    "- Columns of input files\n",
    "- Supplier and Tenant IDs\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Configuration values\n",
    "##############################################################\n",
    "\n",
    "import os\n",
    "\n",
    "# Data Folder and File Names\n",
    "DATA_SRC_DIR                = './data_source'\n",
    "DATA_OUT_DIR                = './data_output'\n",
    "\n",
    "\n",
    "# the original inventory data file\n",
    "INPUT_ORIG_INV_FILE         = os.path.join(DATA_SRC_DIR, 'inventory_parts.csv')\n",
    "# the sku/item id to convert original inventory file to\n",
    "INPUT_PART_NUM_LIST_FILE    = os.path.join(DATA_SRC_DIR, '3m_products.xlsx')\n",
    "# the locations to convert original inventory file to \n",
    "INPUT_LOCATION_LIST_FILE    = os.path.join(DATA_SRC_DIR, '3m_plant_list.txt')\n",
    "\n",
    "# the in-process data file (for debugging and analysis purpose)\n",
    "TEST_DATA_PROCESS_FILE      = os.path.join(DATA_OUT_DIR, 'data_process.xlsx')\n",
    "# the test data output file\n",
    "TEST_DATA_OUTPUT_FILE       = os.path.join(DATA_OUT_DIR, 'testdata_inventory_load.csv')\n",
    "\n",
    "# Chage the original inventory data columns to below. \n",
    "# The process depends on correct identification of part_num, location, and quantity columns\n",
    "INPUT_ORIG_INV_COLUMN       = ['ignore_1','part_num','location','quantity','ignore_2']\n",
    "\n",
    "# Change the input_part_num_list_file colmns to below.\n",
    "# The process depends on correct identification of part_num column\n",
    "INPUT_PART_NUM_COLUMN       = ['ignore-index', 'ignore-Approval Number', 'ignore-Manufacturerâ€™s Donning Procedure User Instructions', 'ignore-Model Number/ Product Line', 'part_num']\n",
    "\n",
    "SUPPLIER_SCBN_ID            = '3M_COMPANY_SD'\n",
    "\n",
    "TENANT_SCBN_ID              = 'S4S_STATE_CA'\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test data file\n",
    "\n",
    "1. load original inventory file\n",
    "1. create mapping from original part # to test data's part #\n",
    "1. create mapping from original location to test data's location"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_input_data_file(filepath: str, columns: [str]) -> (pd.DataFrame, [str], [str]):\n",
    "    # load SCBN supplier list\n",
    "\n",
    "    input_data_file = pd.read_csv(filepath)\n",
    "\n",
    "    input_data_file.columns = columns\n",
    "\n",
    "    part_num_list = input_data_file['part_num'].unique().tolist()\n",
    "\n",
    "    location_list = input_data_file['location'].unique().tolist()\n",
    "\n",
    "    return input_data_file, part_num_list, location_list\n",
    "\n",
    "def read_input_part_num_list(filepath: str, columns:[str]) -> [str]:\n",
    "\n",
    "    product_list_file = pd.read_excel(filepath,\n",
    "            0, # Read the first worksheet\n",
    "            0, # Header is on row 0 (row 1 in Excel's 1base count)\n",
    "            )\n",
    "    \n",
    "    product_list_file.columns = columns\n",
    "\n",
    "    new_sku_list = product_list_file['part_num'].unique().tolist()\n",
    "\n",
    "    return new_sku_list\n",
    "\n",
    "\n",
    "def read_input_location_list(filepath: str, columns:[str]) -> [str]:\n",
    "\n",
    "\n",
    "    new_locations = pd.read_csv(filepath, header=None)\n",
    "\n",
    "    new_locations.columns = columns\n",
    "\n",
    "    new_location_list = new_locations['location'].tolist()\n",
    "\n",
    "    return new_location_list\n",
    "\n",
    "\n",
    "orig_inv_file, orig_part_num_list, orig_location_list = read_input_data_file(INPUT_ORIG_INV_FILE, INPUT_ORIG_INV_COLUMN)\n",
    "\n",
    "new_part_num_list = read_input_part_num_list(INPUT_PART_NUM_LIST_FILE, INPUT_PART_NUM_COLUMN)\n",
    "\n",
    "# part_num_list_shuffled = new_part_num_list.copy()\n",
    "# random.shuffle(part_num_list_shuffled)\n",
    "\n",
    "new_location_list = read_input_location_list(INPUT_LOCATION_LIST_FILE, ['location'])\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create maps"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_part_num_map(orig_part_num_list:[str], new_part_num_list:[str] ) -> pd.DataFrame:\n",
    "\n",
    "    orig_part_num_table = pd.DataFrame(orig_part_num_list, columns=['orig_part_num'])\n",
    "\n",
    "    new_part_num_table = pd.DataFrame(new_part_num_list * int(len(orig_part_num_list)/len(new_part_num_list)+1),\n",
    "        columns=['new_part_num'])\n",
    "\n",
    "    part_num_map = orig_part_num_table.join(new_part_num_table)\n",
    "\n",
    "    return part_num_map\n",
    "\n",
    "\n",
    "def create_location_map(orig_location_list:[str], new_location_list:[str]) -> pd.DataFrame:\n",
    "\n",
    "    old_location_table = pd.DataFrame(orig_location_list, columns=['orig_location'])\n",
    "\n",
    "    new_location_table = pd.DataFrame(new_location_list * int(len(old_location_table)/len(new_location_list)+1), columns=['new_location'])\n",
    "\n",
    "    location_map = old_location_table.join(new_location_table)\n",
    "\n",
    "    return location_map\n",
    "\n",
    "\n",
    "\n",
    "part_num_map = create_part_num_map(orig_part_num_list, new_part_num_list)\n",
    "\n",
    "location_map = create_location_map(orig_location_list, new_location_list)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the original inventory table to the mapping tables"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_new_part_num = orig_inv_file.merge(\n",
    "    part_num_map,\n",
    "    how='left',\n",
    "    left_on = 'part_num',\n",
    "    right_on = 'orig_part_num',\n",
    ")\n",
    "\n",
    "inv_new_partnum_new_location = inv_new_part_num.merge(\n",
    "    location_map,\n",
    "    how = 'left',\n",
    "    left_on = 'location',\n",
    "    right_on = 'orig_location',\n",
    ")\n",
    "\n",
    "test_data_table = inv_new_partnum_new_location.groupby(['new_location', 'new_part_num']).agg({'quantity': ['sum']}).reset_index()\n",
    "\n",
    "test_data_table.columns = ['location id', 'item id', 'quantity']\n",
    "\n",
    "test_data_table['uom'] = '3MPAK'\n",
    "\n",
    "test_data_table['available from'] = '1900-01-01'\n",
    "\n",
    "test_data_table['supplier id'] = SUPPLIER_SCBN_ID\n",
    "\n",
    "test_data_table['customer id'] = TENANT_SCBN_ID\n",
    "\n",
    "# test_data_table['date available from'] = '1900-01-01'\n",
    "\n",
    "# test_data_table['supplier\\'s SCBN id'] = SUPPLIER_SCBN_ID\n",
    "\n",
    "# test_data_table['customer\\'s SCBN id'] = TENANT_SCBN_ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the output file and debug file"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_OUT_DIR):\n",
    "    os.mkdir(DATA_OUT_DIR)\n",
    "\n",
    "# Save test data as a CSV\n",
    "test_data_table.to_csv(TEST_DATA_OUTPUT_FILE, index=False)\n",
    "\n",
    "# persist maps for debug purpose\n",
    "\n",
    "output_writer = pd.ExcelWriter(TEST_DATA_PROCESS_FILE)\n",
    "\n",
    "location_map.to_excel(output_writer, sheet_name='location map')\n",
    "part_num_map.to_excel(output_writer, sheet_name='part num map')\n",
    "\n",
    "# saving the full inventory part dataset takes too long.\n",
    "# inv_new_partnum_new_location.to_excel(output_writer, sheet_name='test data merged')\n",
    "\n",
    "output_writer.save()\n",
    "output_writer.close()\n",
    "\n",
    ""
   ]
  }
 ]
}